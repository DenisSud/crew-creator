
t is an Agent?¶
What is an Agent?

An agent is an autonomous unit programmed to:

Perform tasks
Make decisions
Communicate with other agents

Think of an agent as a member of a team, with specific skills and a particular job to do. Agents can have different roles like 'Researcher', 'Writer', or 'Customer Support', each contributing to the overall goal of the crew.
Agent Attributes¶
AttributeDescription
RoleDefines the agent's function within the crew. It determines the kind of tasks the agent is best suited for.
GoalThe individual objective that the agent aims to achieve. It guides the agent's decision-making process.
BackstoryProvides context to the agent's role and goal, enriching the interaction and collaboration dynamics.
LLM (optional)Represents the language model that will run the agent. It dynamically fetches the model name from the OPENAI_MODEL_NAME environment variable, defaulting to "gpt-4" if not specified.
Tools (optional)Set of capabilities or functions that the agent can use to perform tasks. Expected to be instances of custom classes compatible with the agent's execution environment. Tools are initialized with a default value of an empty list.
Function Calling LLM (optional)Specifies the language model that will handle the tool calling for this agent, overriding the crew function calling LLM if passed. Default is None.
Max Iter (optional)The maximum number of iterations the agent can perform before being forced to give its best answer. Default is 25.
Max RPM (optional)The maximum number of requests per minute the agent can perform to avoid rate limits. It's optional and can be left unspecified, with a default value of None.
max_execution_time (optional)Maximum execution time for an agent to execute a task It's optional and can be left unspecified, with a default value of None, menaning no max execution time
Verbose (optional)Setting this to True configures the internal logger to provide detailed execution logs, aiding in debugging and monitoring. Default is False.
Allow Delegation (optional)Agents can delegate tasks or questions to one another, ensuring that each task is handled by the most suitable agent. Default is True.
Step Callback (optional)A function that is called after each step of the agent. This can be used to log the agent's actions or to perform other operations. It will overwrite the crew step_callback.
Cache (optional)Indicates if the agent should use a cache for tool usage. Default is True.
Creating an Agent¶
Agent Interaction

Agents can interact with each other using crewAI's built-in delegation and communication mechanisms. This allows for dynamic task management and problem-solving within the crew.

To create an agent, you would typically initialize an instance of the Agent class with the desired properties. Here's a conceptual example including all attributes:


# Example: Creating an agent with all attributes
from crewai import Agent

agent = Agent(
	  role='Data Analyst',
	  goal='Extract actionable insights',
	  backstory="""You're a data analyst at a large company.
	  You're responsible for analyzing data and providing insights
	  to the business.
	  You're currently working on a project to analyze the
	  performance of our marketing campaigns.""",
	  tools=[my_tool1, my_tool2],  # Optional, defaults to an empty list
	  llm=my_llm,  # Optional
	  function_calling_llm=my_llm,  # Optional
	  max_iter=15,  # Optional
	  max_rpm=None, # Optional
	  verbose=True,  # Optional
	  allow_delegation=True,  # Optional
	  step_callback=my_intermediate_step_callback,  # Optional
	  cache=True  # Optional
	)
	Conclusion¶
	Agents are the building blocks of the CrewAI framework. By understanding how to define and interact with agents, you can create sophisticated AI systems that leverage the power of collaborative intelligence.
)
Overview of a Task¶
What is a Task?

In the crewAI framework, tasks are specific assignments completed by agents. They provide all necessary details for execution, such as a description, the agent responsible, required tools, and more, facilitating a wide range of action complexities.

Tasks within crewAI can be collaborative, requiring multiple agents to work together. This is managed through the task properties and orchestrated by the Crew's process, enhancing teamwork and efficiency.

Task Attributes¶
AttributeDescription
DescriptionA clear, concise statement of what the task entails.
AgentThe agent responsible for the task, assigned either directly or by the crew's process.
Expected OutputA detailed description of what the task's completion looks like.
Tools (optional)The functions or capabilities the agent can utilize to perform the task.
Async Execution (optional)If set, the task executes asynchronously, allowing progression without waiting for completion.
Context (optional)Specifies tasks whose outputs are used as context for this task.
Config (optional)Additional configuration details for the agent executing the task, allowing further customization.
Output JSON (optional)Outputs a JSON object, requiring an OpenAI client. Only one output format can be set.
Output Pydantic (optional)Outputs a Pydantic model object, requiring an OpenAI client. Only one output format can be set.
Output File (optional)Saves the task output to a file. If used with Output JSON or Output Pydantic, specifies how the output is saved.
Callback (optional)A Python callable that is executed with the task's output upon completion.
Human Input (optional)Indicates if the task requires human feedback at the end, useful for tasks needing human oversight.
Creating a Task¶
Creating a task involves defining its scope, responsible agent, and any additional attributes for flexibility:


from crewai import Task

task = Task(
	    description='Find and summarize the latest and most relevant news on AI',
		    agent=sales_agent
			)
			Task Assignment

			Directly specify an agent for assignment or let the hierarchical CrewAI's process decide based on roles, availability, etc.

			Integrating Tools with Tasks¶
			Leverage tools from the crewAI Toolkit and LangChain Tools for enhanced task performance and agent interaction.

			Creating a Task with Tools¶

			import os
			os.environ["OPENAI_API_KEY"] = "Your Key"
			os.environ["SERPER_API_KEY"] = "Your Key" # serper.dev API key

			from crewai import Agent, Task, Crew
			from crewai_tools import SerperDevTool

			research_agent = Agent(
				  role='Researcher',
				  goal='Find and summarize the latest AI news',
				  backstory="""You're a researcher at a large company.
				  You're responsible for analyzing data and providing insights
				  to the business.""",
				  verbose=True
				)

				search_tool = SerperDevTool()

				task = Task(
					  description='Find and summarize the latest AI news',
					  expected_output='A bullet list summary of the top 5 most important AI news',
					  agent=research_agent,
					  tools=[search_tool]
					)

					crew = Crew(
						    agents=[research_agent],
							    tasks=[task],
								    verbose=2
									)

									result = crew.kickoff()
									print(result)
									This demonstrates how tasks with specific tools can override an agent's default set for tailored task execution.

									Referring to Other Tasks¶
									In crewAI, the output of one task is automatically relayed into the next one, but you can specifically define what tasks' output, including multiple should be used as context for another task.

									This is useful when you have a task that depends on the output of another task that is not performed immediately after it. This is done through the context attribute of the task:


									# ...

									research_ai_task = Task(
										    description='Find and summarize the latest AI news',
											    expected_output='A bullet list summary of the top 5 most important AI news',
												    async_execution=True,
													    agent=research_agent,
														    tools=[search_tool]
															)

															research_ops_task = Task(
																    description='Find and summarize the latest AI Ops news',
																	    expected_output='A bullet list summary of the top 5 most important AI Ops news',
																		    async_execution=True,
																			    agent=research_agent,
																				    tools=[search_tool]
																					)

																					write_blog_task = Task(
																						    description="Write a full blog post about the importance of AI and its latest news",
																							    expected_output='Full blog post that is 4 paragraphs long',
																								    agent=writer_agent,
																									    context=[research_ai_task, research_ops_task]
																										)

																										#...
																										Asynchronous Execution¶
																										You can define a task to be executed asynchronously. This means that the crew will not wait for it to be completed to continue with the next task. This is useful for tasks that take a long time to be completed, or that are not crucial for the next tasks to be performed.

																										You can then use the context attribute to define in a future task that it should wait for the output of the asynchronous task to be completed.


																										#...

																										list_ideas = Task(
																											    description="List of 5 interesting ideas to explore for an article about AI.",
																												    expected_output="Bullet point list of 5 ideas for an article.",
																													    agent=researcher,
																														    async_execution=True # Will be executed asynchronously
																															)

																															list_important_history = Task(
																																    description="Research the history of AI and give me the 5 most important events.",
																																	    expected_output="Bullet point list of 5 important events.",
																																		    agent=researcher,
																																			    async_execution=True # Will be executed asynchronously
																																				)

																																				write_article = Task(
																																					    description="Write an article about AI, its history, and interesting ideas.",
																																						    expected_output="A 4 paragraph article about AI.",
																																							    agent=writer,
																																								    context=[list_ideas, list_important_history] # Will wait for the output of the two tasks to be completed
																																									)

																																									#...
																																									Callback Mechanism¶
																																									The callback function is executed after the task is completed, allowing for actions or notifications to be triggered based on the task's outcome.


																																									# ...

																																									def callback_function(output: TaskOutput):
																																									    # Do something after the task is completed
																																										    # Example: Send an email to the manager
																																											    print(f"""
																																												        Task completed!
																																														        Task: {output.description}
																																																        Output: {output.raw_output}
																																																		    """)
																																																			
																																																			research_task = Task(
																																																				    description='Find and summarize the latest AI news',
																																																					    expected_output='A bullet list summary of the top 5 most important AI news',
																																																						    agent=research_agent,
																																																							    tools=[search_tool],
																																																								    callback=callback_function
																																																									)

																																																									#...
																																																									Accessing a Specific Task Output¶
																																																									Once a crew finishes running, you can access the output of a specific task by using the output attribute of the task object:


																																																									# ...
																																																									task1 = Task(
																																																										    description='Find and summarize the latest AI news',
																																																											    expected_output='A bullet list summary of the top 5 most important AI news',
																																																												    agent=research_agent,
																																																													    tools=[search_tool]
																																																														)

																																																														#...

																																																														crew = Crew(
																																																															    agents=[research_agent],
																																																																    tasks=[task1, task2, task3],
																																																																	    verbose=2
																																																																		)

																																																																		result = crew.kickoff()

																																																																		# Returns a TaskOutput object with the description and results of the task
																																																																		print(f"""
																																																																		    Task completed!
																																																																			    Task: {task1.output.description}
																																																																				    Output: {task1.output.raw_output}
																																																																					""")
																																																																					Tool Override Mechanism¶
																																																																					Specifying tools in a task allows for dynamic adaptation of agent capabilities, emphasizing CrewAI's flexibility.
																																																																					
																																																																					Error Handling and Validation Mechanisms¶
																																																																					While creating and executing tasks, certain validation mechanisms are in place to ensure the robustness and reliability of task attributes. These include but are not limited to:
																																																																					
																																																																					Ensuring only one output type is set per task to maintain clear output expectations.
																																																																					Preventing the manual assignment of the id attribute to uphold the integrity of the unique identifier system.
																																																																					These validations help in maintaining the consistency and reliability of task executions within the crewAI framework.
																																																																					
																																																																					Conclusion¶
																																																																					Tasks are the driving force behind the actions of agents in crewAI. By properly defining tasks and their outcomes, you set the stage for your AI agents to work effectively, either independently or as a collaborative unit. Equipping tasks with appropriate tools, understanding the execution process, and following robust validation practices are crucial for maximizing CrewAI's potential, ensuring agents are effectively prepared for their assignments and that tasks are executed as intended.")

																																																	
																																																														)
																																																									)
																																																			)")
																																				)
																															)
																										)
																					)
															)
									)
					)
				)
			)
)
Introduction¶
CrewAI tools empower agents with capabilities ranging from web searching and data analysis to collaboration and delegating tasks among coworkers. This documentation outlines how to create, integrate, and leverage these tools within the CrewAI framework, including a new focus on collaboration tools.

What is a Tool?¶
Definition

A tool in CrewAI is a skill or function that agents can utilize to perform various actions. This includes tools from the crewAI Toolkit and LangChain Tools, enabling everything from simple searches to complex interactions and effective teamwork among agents.

Key Characteristics of Tools¶
Utility: Crafted for tasks such as web searching, data analysis, content generation, and agent collaboration.
Integration: Boosts agent capabilities by seamlessly integrating tools into their workflow.
Customizability: Provides the flexibility to develop custom tools or utilize existing ones, catering to the specific needs of agents.
Error Handling: Incorporates robust error handling mechanisms to ensure smooth operation.
Caching Mechanism: Features intelligent caching to optimize performance and reduce redundant operations.
Using crewAI Tools¶
To enhance your agents' capabilities with crewAI tools, begin by installing our extra tools package:


pip install 'crewai[tools]'
Here's an example demonstrating their use:


import os
from crewai import Agent, Task, Crew
# Importing crewAI tools
from crewai_tools import (
	    DirectoryReadTool,
		    FileReadTool,
			    SerperDevTool,
				    WebsiteSearchTool
					)

					# Set up API keys
					os.environ["SERPER_API_KEY"] = "Your Key" # serper.dev API key
					os.environ["OPENAI_API_KEY"] = "Your Key"

					# Instantiate tools
					docs_tool = DirectoryReadTool(directory='./blog-posts')
					file_tool = FileReadTool()
					search_tool = SerperDevTool()
					web_rag_tool = WebsiteSearchTool()

					# Create agents
					researcher = Agent(
						    role='Market Research Analyst',
							    goal='Provide up-to-date market analysis of the AI industry',
								    backstory='An expert analyst with a keen eye for market trends.',
									    tools=[search_tool, web_rag_tool],
										    verbose=True
											)

											writer = Agent(
												    role='Content Writer',
													    goal='Craft engaging blog posts about the AI industry',
														    backstory='A skilled writer with a passion for technology.',
															    tools=[docs_tool, file_tool],
																    verbose=True
																	)

																	# Define tasks
																	research = Task(
																		    description='Research the latest trends in the AI industry and provide a summary.',
																			    expected_output='A summary of the top 3 trending developments in the AI industry with a unique perspective on their significance.',
																				    agent=researcher
																					)

																					write = Task(
																						    description='Write an engaging blog post about the AI industry, based on the research analyst’s summary. Draw inspiration from the latest blog posts in the directory.',
																							    expected_output='A 4-paragraph blog post formatted in markdown with engaging, informative, and accessible content, avoiding complex jargon.',
																								    agent=writer,
																									    output_file='blog-posts/new_post.md'  # The final blog post will be saved here
																										)

																										# Assemble a crew
																										crew = Crew(
																											    agents=[researcher, writer],
																												    tasks=[research, write],
																													    verbose=2
																														)

																														# Execute tasks
																														crew.kickoff()
																														Available crewAI Tools¶
																														Error Handling: All tools are built with error handling capabilities, allowing agents to gracefully manage exceptions and continue their tasks.
																														Caching Mechanism: All tools support caching, enabling agents to efficiently reuse previously obtained results, reducing the load on external resources and speeding up the execution time, you can also define finner control over the caching mechanism, using cache_function attribute on the tool.
																														Here is a list of the available tools and their descriptions:

																														ToolDescription
																														CodeDocsSearchToolA RAG tool optimized for searching through code documentation and related technical documents.
																														CSVSearchToolA RAG tool designed for searching within CSV files, tailored to handle structured data.
																														DirectorySearchToolA RAG tool for searching within directories, useful for navigating through file systems.
																														DOCXSearchToolA RAG tool aimed at searching within DOCX documents, ideal for processing Word files.
																														DirectoryReadToolFacilitates reading and processing of directory structures and their contents.
																														FileReadToolEnables reading and extracting data from files, supporting various file formats.
																														GithubSearchToolA RAG tool for searching within GitHub repositories, useful for code and documentation search.
																														SerperDevToolA specialized tool for development purposes, with specific functionalities under development.
																														TXTSearchToolA RAG tool focused on searching within text (.txt) files, suitable for unstructured data.
																														JSONSearchToolA RAG tool designed for searching within JSON files, catering to structured data handling.
																														MDXSearchToolA RAG tool tailored for searching within Markdown (MDX) files, useful for documentation.
																														PDFSearchToolA RAG tool aimed at searching within PDF documents, ideal for processing scanned documents.
																														PGSearchToolA RAG tool optimized for searching within PostgreSQL databases, suitable for database queries.
																														RagToolA general-purpose RAG tool capable of handling various data sources and types.
																														ScrapeElementFromWebsiteToolEnables scraping specific elements from websites, useful for targeted data extraction.
																														ScrapeWebsiteToolFacilitates scraping entire websites, ideal for comprehensive data collection.
																														WebsiteSearchToolA RAG tool for searching website content, optimized for web data extraction.
																														XMLSearchToolA RAG tool designed for searching within XML files, suitable for structured data formats.
																														YoutubeChannelSearchToolA RAG tool for searching within YouTube channels, useful for video content analysis.
																														YoutubeVideoSearchToolA RAG tool aimed at searching within YouTube videos, ideal for video data extraction.
																														Creating your own Tools¶
																														Custom Tool Creation

																														Developers can craft custom tools tailored for their agent’s needs or utilize pre-built options:

																														To create your own crewAI tools you will need to install our extra tools package:


																														pip install 'crewai[tools]'
																														Once you do that there are two main ways for one to create a crewAI tool:

																														Subclassing BaseTool¶

																														from crewai_tools import BaseTool

																														class MyCustomTool(BaseTool):
																														    name: str = "Name of my tool"
																															    description: str = "Clear description for what this tool is useful for, you agent will need this information to use it."

																																    def _run(self, argument: str) -> str:
																																	        # Implementation goes here
																																			        return "Result from custom tool"
																																					Utilizing the tool Decorator¶

																																					from crewai_tools import tool
																																					@tool("Name of my tool")
																																					def my_tool(question: str) -> str:
																																					    """Clear description for what this tool is useful for, you agent will need this information to use it."""
																																						    # Function logic here
																																							    return "Result from your custom tool"
																																								Custom Caching Mechanism¶
																																								Caching

																																								Tools can optionally implement a cache_function to fine-tune caching behavior. This function determines when to cache results based on specific conditions, offering granular control over caching logic.


																																								from crewai_tools import tool

																																								@tool
																																								def multiplication_tool(first_number: int, second_number: int) -> str:
																																								    """Useful for when you need to multiply two numbers together."""
																																									    return first_number * second_number

																																										def cache_func(args, result):
																																										    # In this case, we only cache the result if it's a multiple of 2
																																											    cache = result % 2 == 0
																																												    return cache

																																													multiplication_tool.cache_function = cache_func

																																													writer1 = Agent(
																																														        role="Writer",
																																																        goal="You write lesssons of math for kids.",
																																																		        backstory="You're an expert in writting and you love to teach kids but you know nothing of math.",
																																																				        tools=[multiplcation_tool],
																																																						        allow_delegation=False,
																																																								    )
																																																									    #...
																																																										Using LangChain Tools¶
																																																										LangChain Integration

																																																										CrewAI seamlessly integrates with LangChain’s comprehensive toolkit for search-based queries and more, here are the available built-in tools that are offered by Langchain LangChain Toolkit

																																																										:


																																																										from crewai import Agent
																																																										from langchain.agents import Tool
																																																										from langchain.utilities import GoogleSerperAPIWrapper

																																																										# Setup API keys
																																																										os.environ["SERPER_API_KEY"] = "Your Key"

																																																										search = GoogleSerperAPIWrapper()

																																																										# Create and assign the search tool to an agent
																																																										serper_tool = Tool(
																																																											  name="Intermediate Answer",
																																																											  func=search.run,
																																																											  description="Useful for search-based queries",
																																																											)

																																																											agent = Agent(
																																																												  role='Research Analyst',
																																																												  goal='Provide up-to-date market analysis',
																																																												  backstory='An expert analyst with a keen eye for market trends.',
																																																												  tools=[serper_tool]
																																																												)

																																																												# rest of the code ...
																																																												Conclusion¶
																																																												Tools are pivotal in extending the capabilities of CrewAI agents, enabling them to undertake a broad spectrum of tasks and collaborate effectively. When building solutions with CrewAI, leverage both custom and existing tools to empower your agents and enhance the AI ecosystem. Consider utilizing error handling, caching mechanisms, and the flexibility of tool arguments to optimize your agents' performance and capabilities.
																																																											)
																																																										)
																																													)
																										)
																					)
																	)
											)
					)
)
esses
Understanding Processes¶
Core Concept

In CrewAI, processes orchestrate the execution of tasks by agents, akin to project management in human teams. These processes ensure tasks are distributed and executed efficiently, in alignment with a predefined strategy.

Process Implementations¶
Sequential: Executes tasks sequentially, ensuring tasks are completed in an orderly progression.
Hierarchical: Organizes tasks in a managerial hierarchy, where tasks are delegated and executed based on a structured chain of command. A manager language model (manager_llm) must be specified in the crew to enable the hierarchical process, facilitating the creation and management of tasks by the manager.
Consensual Process (Planned): Aiming for collaborative decision-making among agents on task execution, this process type introduces a democratic approach to task management within CrewAI. It is planned for future development and is not currently implemented in the codebase.
The Role of Processes in Teamwork¶
Processes enable individual agents to operate as a cohesive unit, streamlining their efforts to achieve common objectives with efficiency and coherence.

Assigning Processes to a Crew¶
To assign a process to a crew, specify the process type upon crew creation to set the execution strategy. For a hierarchical process, ensure to define manager_llm for the manager agent.


from crewai import Crew
from crewai.process import Process
from langchain_openai import ChatOpenAI

# Example: Creating a crew with a sequential process
crew = Crew(
	    agents=my_agents,
		    tasks=my_tasks,
			    process=Process.sequential
				)

				# Example: Creating a crew with a hierarchical process
				# Ensure to provide a manager_llm
				crew = Crew(
					    agents=my_agents,
						    tasks=my_tasks,
							    process=Process.hierarchical,
								    manager_llm=ChatOpenAI(model="gpt-4")
									)
									Note: Ensure my_agents and my_tasks are defined prior to creating a Crew object, and for the hierarchical process, manager_llm is also required.
									Sequential Process¶
									This method mirrors dynamic team workflows, progressing through tasks in a thoughtful and systematic manner. Task execution follows the predefined order in the task list, with the output of one task serving as context for the next.

									To customize task context, utilize the context parameter in the Task class to specify outputs that should be used as context for subsequent tasks.

									Hierarchical Process¶
									Emulates a corporate hierarchy, CrewAI automatically creates a manager for you, requiring the specification of a manager language model (manager_llm) for the manager agent. This agent oversees task execution, including planning, delegation, and validation. Tasks are not pre-assigned; the manager allocates tasks to agents based on their capabilities, reviews outputs, and assesses task completion.

									Process Class: Detailed Overview¶
									The Process class is implemented as an enumeration (Enum), ensuring type safety and restricting process values to the defined types (sequential, hierarchical). The consensual process is planned for future inclusion, emphasizing our commitment to continuous development and innovation.

									Additional Task Features¶
									Asynchronous Execution: Tasks can now be executed asynchronously, allowing for parallel processing and efficiency improvements. This feature is designed to enable tasks to be carried out concurrently, enhancing the overall productivity of the crew.
									Human Input Review: An optional feature that enables the review of task outputs by humans to ensure quality and accuracy before finalization. This additional step introduces a layer of oversight, providing an opportunity for human intervention and validation.
									Output Customization: Tasks support various output formats, including JSON (output_json), Pydantic models (output_pydantic), and file outputs (output_file), providing flexibility in how task results are captured and utilized. This allows for a wide range of output possibilities, catering to different needs and requirements.
									Conclusion¶
									The structured collaboration facilitated by processes within CrewAI is crucial for enabling systematic teamwork among agents. This documentation has been updated to reflect the latest features, enhancements, and the planned integration of the Consensual Process, ensuring users have access to the most current and comprehensive information.


									
				)
)
What is a Crew?¶
A crew in crewAI represents a collaborative group of agents working together to achieve a set of tasks. Each crew defines the strategy for task execution, agent collaboration, and the overall workflow.

Crew Attributes¶
AttributeDescription
TasksA list of tasks assigned to the crew.
AgentsA list of agents that are part of the crew.
Process (optional)The process flow (e.g., sequential, hierarchical) the crew follows.
Verbose (optional)The verbosity level for logging during execution.
Manager LLM (optional)The language model used by the manager agent in a hierarchical process. Required when using a hierarchical process.
Function Calling LLM (optional)If passed, the crew will use this LLM to do function calling for tools for all agents in the crew. Each agent can have its own LLM, which overrides the crew's LLM for function calling.
Config (optional)Optional configuration settings for the crew, in Json or Dict[str, Any] format.
Max RPM (optional)Maximum requests per minute the crew adheres to during execution.
Language (optional)Language used for the crew, defaults to English.
Language File (optional)Path to the language file to be used for the crew.
Memory (optional)Utilized for storing execution memories (short-term, long-term, entity memory).
Cache (optional)Specifies whether to use a cache for storing the results of tools' execution.
Embedder (optional)Configuration for the embedder to be used by the crew. mostly used by memory for now
Full Output (optional)Whether the crew should return the full output with all tasks outputs or just the final output.
Step Callback (optional)A function that is called after each step of every agent. This can be used to log the agent's actions or to perform other operations; it won't override the agent-specific step_callback.
Task Callback (optional)A function that is called after the completion of each task. Useful for monitoring or additional operations post-task execution.
Share Crew (optional)Whether you want to share the complete crew information and execution with the crewAI team to make the library better, and allow us to train models.
Output Log File (optional)Whether you want to have a file with the complete crew output and execution. You can set it using True and it will default to the folder you are currently and it will be called logs.txt or passing a string with the full path and name of the file.
Crew Max RPM

The max_rpm attribute sets the maximum number of requests per minute the crew can perform to avoid rate limits and will override individual agents' max_rpm settings if you set it.

Creating a Crew¶
When assembling a crew, you combine agents with complementary roles and tools, assign tasks, and select a process that dictates their execution order and interaction.

Example: Assembling a Crew¶

from crewai import Crew, Agent, Task, Process
from langchain_community.tools import DuckDuckGoSearchRun

# Define agents with specific roles and tools
researcher = Agent(
	    role='Senior Research Analyst',
		    goal='Discover innovative AI technologies',
			    tools=[DuckDuckGoSearchRun()]
				)

				writer = Agent(
					    role='Content Writer',
						    goal='Write engaging articles on AI discoveries',
							    verbose=True
								)

								# Create tasks for the agents
								research_task = Task(
									    description='Identify breakthrough AI technologies',
										    agent=researcher
											)
											write_article_task = Task(
												    description='Draft an article on the latest AI technologies',
													    agent=writer
														)

														# Assemble the crew with a sequential process
														my_crew = Crew(
															    agents=[researcher, writer],
																    tasks=[research_task, write_article_task],
																	    process=Process.sequential,
																		    full_output=True,
																			    verbose=True,
																				)
																				Memory Utilization¶
																				Crews can utilize memory (short-term, long-term, and entity memory) to enhance their execution and learning over time. This feature allows crews to store and recall execution memories, aiding in decision-making and task execution strategies.

																				Cache Utilization¶
																				Caches can be employed to store the results of tools' execution, making the process more efficient by reducing the need to re-execute identical tasks.

																				Crew Usage Metrics¶
																				After the crew execution, you can access the usage_metrics attribute to view the language model (LLM) usage metrics for all tasks executed by the crew. This provides insights into operational efficiency and areas for improvement.


																				# Access the crew's usage metrics
																				crew = Crew(agents=[agent1, agent2], tasks=[task1, task2])
																				crew.kickoff()
																				print(crew.usage_metrics)
																				Crew Execution Process¶
																				Sequential Process: Tasks are executed one after another, allowing for a linear flow of work.
																				Hierarchical Process: A manager agent coordinates the crew, delegating tasks and validating outcomes before proceeding. Note: A manager_llm is required for this process and it's essential for validating the process flow.
																				Kicking Off a Crew¶
																				Once your crew is assembled, initiate the workflow with the kickoff() method. This starts the execution process according to the defined process flow.


																				# Start the crew's task execution
																				result = my_crew.kickoff()
																				print(result)
														)
											)
								)
				)
)

Collaboration Fundamentals¶
Core of Agent Interaction

Collaboration in CrewAI is fundamental, enabling agents to combine their skills, share information, and assist each other in task execution, embodying a truly cooperative ecosystem.

Information Sharing: Ensures all agents are well-informed and can contribute effectively by sharing data and findings.
Task Assistance: Allows agents to seek help from peers with the required expertise for specific tasks.
Resource Allocation: Optimizes task execution through the efficient distribution and sharing of resources among agents.
Enhanced Attributes for Improved Collaboration¶
The Crew class has been enriched with several attributes to support advanced functionalities:

Language Model Management (manager_llm, function_calling_llm): Manages language models for executing tasks and tools, facilitating sophisticated agent-tool interactions. Note that while manager_llm is mandatory for hierarchical processes to ensure proper execution flow, function_calling_llm is optional, with a default value provided for streamlined tool interaction.
Process Flow (process): Defines the execution logic (e.g., sequential, hierarchical) to streamline task distribution and execution.
Verbose Logging (verbose): Offers detailed logging capabilities for monitoring and debugging purposes. It supports both integer and boolean types to indicate the verbosity level. For example, setting verbose to 1 might enable basic logging, whereas setting it to True enables more detailed logs.
Rate Limiting (max_rpm): Ensures efficient utilization of resources by limiting requests per minute. Guidelines for setting max_rpm should consider the complexity of tasks and the expected load on resources.
Internationalization Support (language, language_file): Facilitates operation in multiple languages, enhancing global usability. Supported languages and the process for utilizing the language_file attribute for customization should be clearly documented.
Execution and Output Handling (full_output): Distinguishes between full and final outputs for nuanced control over task results. Examples showcasing the difference in outputs can aid in understanding the practical implications of this attribute.
Callback and Telemetry (step_callback, task_callback): Integrates callbacks for step-wise and task-level execution monitoring, alongside telemetry for performance analytics. The purpose and usage of task_callback alongside step_callback for granular monitoring should be clearly explained.
Crew Sharing (share_crew): Enables sharing of crew information with CrewAI for continuous improvement and training models. The privacy implications and benefits of this feature, including how it contributes to model improvement, should be outlined.
Usage Metrics (usage_metrics): Stores all metrics for the language model (LLM) usage during all tasks' execution, providing insights into operational efficiency and areas for improvement. Detailed information on accessing and interpreting these metrics for performance analysis should be provided.
Memory Usage (memory): Indicates whether the crew should use memory to store memories of its execution, enhancing task execution and agent learning.
Embedder Configuration (embedder): Specifies the configuration for the embedder to be used by the crew for understanding and generating language. This attribute supports customization of the language model provider.
Delegation: Dividing to Conquer¶
Delegation enhances functionality by allowing agents to intelligently assign tasks or seek help, thereby amplifying the crew's overall capability.

Implementing Collaboration and Delegation¶
Setting up a crew involves defining the roles and capabilities of each agent. CrewAI seamlessly manages their interactions, ensuring efficient collaboration and delegation, with enhanced customization and monitoring features to adapt to various operational needs.

Example Scenario¶
Consider a crew with a researcher agent tasked with data gathering and a writer agent responsible for compiling reports. The integration of advanced language model management and process flow attributes allows for more sophisticated interactions, such as the writer delegating complex research tasks to the researcher or querying specific information, thereby facilitating a seamless workflow.

Conclusion¶
The integration of advanced attributes and functionalities into the CrewAI framework significantly enriches the agent collaboration ecosystem. These enhancements not only simplify interactions but also offer unprecedented flexibility and control, paving the way for sophisticated AI-driven solutions capable of tackling complex tasks through intelligent collaboration and delegation.
